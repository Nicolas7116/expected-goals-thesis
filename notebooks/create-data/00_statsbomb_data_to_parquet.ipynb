{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the StatsBomb json files and turns them into parquet files. These are extremely fast to load so good for this prototyping kind of analysis.\n",
    "\n",
    "# This update\n",
    "This analysis has been re-run from the commit 2381d6b0afbf59b93c0a41dd4cc017f4cbbc4d9b:\n",
    "https://github.com/statsbomb/open-data/commit/2381d6b0afbf59b93c0a41dd4cc017f4cbbc4d9b.\n",
    "\n",
    "From this commit, the dataframes have the following number of entries:\n",
    "\n",
    "- df_competition: 42 entries\n",
    "- df_match: 1,242 entries (10 event files aren't included in the match file)\n",
    "- df_lineup: 42,035 entries\n",
    "- df_event: 4,420,124 entries\n",
    "- df_freeze: 400,976 entries\n",
    "- df_tactic: 53,933 entries\n",
    "- df_related: 8,521,814 entries\n",
    "\n",
    "\n",
    "# Rerunning the analysis from the original thesis:\n",
    "Note the original analysis for this thesis was run from the commit 87a5f02d7f526c4fe92909790999da5f26166328:\n",
    "https://github.com/statsbomb/open-data/commit/87a5f02d7f526c4fe92909790999da5f26166328. If you want to re-run the thesis analysis checkout the commit with the command: git checkout 87a5f02d7f526c4fe92909790999da5f2616632."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mplsoccer import Sblocal\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change these paths/ parameters\n",
    "You will need to change these paths/ parameters depending on where the StatsBomb open-data is located, how and where you want to save the resulting data, and if you only want the new files to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data folder is one folder down in the directory. To change if run elsewhere\n",
    "STATSBOMB_DATA = os.path.join('..', '..', '..', 'open-data', 'data')\n",
    "# save files in folder in current directory. To change if want to save elsewhere\n",
    "DATA_FOLDER = os.path.join('..', '..', 'data', 'statsbomb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_links = glob.glob(os.path.join(STATSBOMB_DATA, 'events', '**', '*.json'), recursive=True)\n",
    "lineup_links = glob.glob(os.path.join(STATSBOMB_DATA, 'lineups', '**', '*.json'), recursive=True)\n",
    "match_links = glob.glob(os.path.join(STATSBOMB_DATA, 'matches', '**', '*.json'), recursive=True)\n",
    "competition_path = os.path.join(STATSBOMB_DATA, 'competitions.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the directory structure\n",
    "for folder in ['event_raw', 'related_raw', 'freeze_raw', 'tactic_raw', 'lineup_raw']:\n",
    "    path = os.path.join(DATA_FOLDER, folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create StatsBomb Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Sblocal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74 entries, 0 to 73\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   competition_id             74 non-null     int64 \n",
      " 1   season_id                  74 non-null     int64 \n",
      " 2   country_name               74 non-null     object\n",
      " 3   competition_name           74 non-null     object\n",
      " 4   competition_gender         74 non-null     object\n",
      " 5   competition_youth          74 non-null     bool  \n",
      " 6   competition_international  74 non-null     bool  \n",
      " 7   season_name                74 non-null     object\n",
      " 8   match_updated              74 non-null     object\n",
      " 9   match_updated_360          56 non-null     object\n",
      " 10  match_available_360        10 non-null     object\n",
      " 11  match_available            74 non-null     object\n",
      "dtypes: bool(2), int64(2), object(8)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_competition = parser.competition(competition_path)\n",
    "df_competition.to_parquet(os.path.join(DATA_FOLDER, 'competition.parquet'), allow_truncated_timestamps=True)\n",
    "df_competition.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep a copy of the match dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_path = os.path.join(DATA_FOLDER, 'match.parquet')\n",
    "if os.path.exists(match_path):\n",
    "    df_match_copy = pd.read_parquet(match_path).copy()\n",
    "    UPDATE_FILES = True\n",
    "else:\n",
    "    UPDATE_FILES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3433 entries, 0 to 33\n",
      "Data columns (total 52 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   match_id                         3433 non-null   int64         \n",
      " 1   match_date                       3433 non-null   datetime64[ns]\n",
      " 2   kick_off                         3428 non-null   datetime64[ns]\n",
      " 3   home_score                       3433 non-null   int64         \n",
      " 4   away_score                       3433 non-null   int64         \n",
      " 5   match_status                     3433 non-null   object        \n",
      " 6   match_status_360                 3433 non-null   object        \n",
      " 7   last_updated                     3433 non-null   datetime64[ns]\n",
      " 8   last_updated_360                 1797 non-null   datetime64[ns]\n",
      " 9   match_week                       3433 non-null   int64         \n",
      " 10  competition_id                   3433 non-null   int64         \n",
      " 11  country_name                     3433 non-null   object        \n",
      " 12  competition_name                 3433 non-null   object        \n",
      " 13  season_id                        3433 non-null   int64         \n",
      " 14  season_name                      3433 non-null   object        \n",
      " 15  home_team_id                     3433 non-null   int64         \n",
      " 16  home_team_name                   3433 non-null   object        \n",
      " 17  home_team_gender                 3433 non-null   object        \n",
      " 18  home_team_group                  184 non-null    object        \n",
      " 19  home_team_country_id             3433 non-null   int64         \n",
      " 20  home_team_country_name           3433 non-null   object        \n",
      " 21  home_team_managers_id            3349 non-null   float64       \n",
      " 22  home_team_managers_name          3349 non-null   object        \n",
      " 23  home_team_managers_nickname      3349 non-null   object        \n",
      " 24  home_team_managers_dob           3333 non-null   datetime64[ns]\n",
      " 25  home_team_managers_country_id    3349 non-null   float64       \n",
      " 26  home_team_managers_country_name  3349 non-null   object        \n",
      " 27  away_team_id                     3433 non-null   int64         \n",
      " 28  away_team_name                   3433 non-null   object        \n",
      " 29  away_team_gender                 3433 non-null   object        \n",
      " 30  away_team_group                  186 non-null    object        \n",
      " 31  away_team_country_id             3433 non-null   int64         \n",
      " 32  away_team_country_name           3433 non-null   object        \n",
      " 33  away_team_managers_id            3350 non-null   float64       \n",
      " 34  away_team_managers_name          3350 non-null   object        \n",
      " 35  away_team_managers_nickname      3350 non-null   object        \n",
      " 36  away_team_managers_dob           3334 non-null   datetime64[ns]\n",
      " 37  away_team_managers_country_id    3350 non-null   float64       \n",
      " 38  away_team_managers_country_name  3350 non-null   object        \n",
      " 39  metadata_data_version            3431 non-null   object        \n",
      " 40  metadata_shot_fidelity_version   3235 non-null   object        \n",
      " 41  metadata_xy_fidelity_version     3189 non-null   object        \n",
      " 42  competition_stage_id             3433 non-null   int64         \n",
      " 43  competition_stage_name           3433 non-null   object        \n",
      " 44  stadium_id                       3423 non-null   float64       \n",
      " 45  stadium_name                     3423 non-null   object        \n",
      " 46  stadium_country_id               3423 non-null   float64       \n",
      " 47  stadium_country_name             3423 non-null   object        \n",
      " 48  referee_id                       3233 non-null   float64       \n",
      " 49  referee_name                     3233 non-null   object        \n",
      " 50  referee_country_id               3233 non-null   float64       \n",
      " 51  referee_country_name             3233 non-null   object        \n",
      "dtypes: datetime64[ns](6), float64(8), int64(11), object(27)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "match_dfs = [parser.match(file) for file in match_links]\n",
    "df_match = pd.concat(match_dfs)\n",
    "# again there is a slight loss of quality when saving timestamps, but only relevant for last_updated\n",
    "df_match.to_parquet(os.path.join(DATA_FOLDER, 'match.parquet'),\n",
    "                    allow_truncated_timestamps=True)\n",
    "df_match.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check which games have been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UPDATE_FILES:\n",
    "    df_match_copy = (df_match[['match_id', 'last_updated']]\n",
    "                     .merge(df_match_copy[['match_id', 'last_updated']],\n",
    "                            how='left', suffixes=['', '_old'], on='match_id'))\n",
    "    df_match_copy = df_match_copy[(df_match_copy.last_updated.dt.floor('ms') !=\n",
    "                                   df_match_copy.last_updated_old.dt.floor('ms'))].copy()\n",
    "    to_update = df_match_copy.match_id.unique()\n",
    "\n",
    "    # get array of event links to update - based on whether they have been updated in the match json\n",
    "    event_link_ids = [int(os.path.splitext(os.path.basename(link))[0]) for link in event_links]\n",
    "    event_to_update = [link in to_update for link in event_link_ids]\n",
    "    event_links = np.array(event_links)[event_to_update]\n",
    "\n",
    "    # get array of lineup links to update -\n",
    "    # based on whether they have been updated in the match jsons\n",
    "    lineup_link_ids = [int(os.path.splitext(os.path.basename(link))[0]) for link in lineup_links]\n",
    "    lineup_to_update = [link in to_update for link in lineup_link_ids]\n",
    "    lineup_links = np.array(lineup_links)[lineup_to_update]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the lineup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [01:11<00:00, 48.23it/s]\n"
     ]
    }
   ],
   "source": [
    "LINEUP_FOLDER = os.path.join(DATA_FOLDER, 'lineup_raw')\n",
    "# loop through all the changed links and store as parquet files - small and fast files\n",
    "for file in tqdm(lineup_links):\n",
    "    save_path = f'{os.path.basename(file)[:-4]}parquet'\n",
    "    try:\n",
    "        df_lineup = parser.lineup(file)\n",
    "        df_lineup.to_parquet(os.path.join(LINEUP_FOLDER, save_path))\n",
    "    except ValueError:\n",
    "        print('Skipping file:', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players with split ids\n",
    "to_replace = {18103: 38522}  # Dietmar Hamann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [00:53<00:00, 64.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 130488 entries, 0 to 35\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   player_id        130488 non-null  int64  \n",
      " 1   player_name      130488 non-null  object \n",
      " 2   player_nickname  130488 non-null  object \n",
      " 3   jersey_number    130488 non-null  int64  \n",
      " 4   match_id         130488 non-null  int64  \n",
      " 5   team_id          130488 non-null  int64  \n",
      " 6   team_name        130488 non-null  object \n",
      " 7   country_id       130475 non-null  float64\n",
      " 8   country_name     130475 non-null  object \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 10.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_29060\\1261813975.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_lineup.player_id.replace(to_replace, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "if len(lineup_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    lineup_files = glob.glob(os.path.join(LINEUP_FOLDER, '*.parquet'))\n",
    "    df_lineup = pd.concat([pd.read_parquet(file) for file in tqdm(lineup_files)])\n",
    "    # replace some ids that appear to be split\n",
    "    df_lineup.player_id.replace(to_replace, inplace=True)\n",
    "    df_lineup.to_parquet(os.path.join(DATA_FOLDER, 'lineup.parquet'))\n",
    "    df_lineup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [19:28<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all the changed links and store as parquet files - small and fast files\n",
    "for file in tqdm(event_links):\n",
    "    save_path = f'{os.path.basename(file)[:-4]}parquet'\n",
    "    try:\n",
    "        events, related, freeze, tactics = parser.event(file)\n",
    "        # save to parquet files\n",
    "        # using the dictionary key to access the dataframes from the dictionary\n",
    "        events.to_parquet(os.path.join(DATA_FOLDER, 'event_raw', save_path))\n",
    "        related.to_parquet(os.path.join(DATA_FOLDER, 'related_raw', save_path))\n",
    "        freeze.to_parquet(os.path.join(DATA_FOLDER, 'freeze_raw', save_path))\n",
    "        tactics.to_parquet(os.path.join(DATA_FOLDER, 'tactic_raw', save_path))\n",
    "    except ValueError:\n",
    "        print('Skipping:', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If updating the event dataframe get a list of ids to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_files = glob.glob(os.path.join(DATA_FOLDER, 'event_raw', '*.parquet'))\n",
    "if UPDATE_FILES:\n",
    "    ids_to_update = [int(os.path.splitext(os.path.basename(link))[0]) for link in event_links]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load old dataframe and combine with updated parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(directory, file_type, update_ids):\n",
    "    \"\"\" Update an old DataFrame with files that have changed/ been added.\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : path to directory containing the files\n",
    "    file_type : str\n",
    "        One of 'event', 'freeze', 'tatic', or related'\n",
    "    update_ids : list of integers\n",
    "        A list of the match ids to update\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        An updated DataFrame with the new/changed matches.\n",
    "    \"\"\"\n",
    "    # get a list of parquet files to add to the old dataframe\n",
    "    files = glob.glob(os.path.join(directory, f'{file_type}_raw', '*.parquet'))\n",
    "    files_id = [int(os.path.splitext(os.path.basename(file))[0]) for file in files]\n",
    "    mask_update = [match_id in update_ids for match_id in files_id]\n",
    "    files = np.array(files)[mask_update]\n",
    "    # load the old dataframe, filter out changed matches and add the new parquet files\n",
    "    df_old = pd.read_parquet(os.path.join(directory, f'{file_type}.parquet'))\n",
    "    df_old = df_old[~df_old.match_id.isin(update_ids)]\n",
    "    df_new = pd.concat([pd.read_parquet(file) for file in tqdm(files)])\n",
    "    df_old = pd.concat([df_old, df_new])\n",
    "    return df_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single dataframe events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [01:37<00:00, 35.09it/s]\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_29060\\3132692631.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_event.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12083338 entries, 0 to 3656\n",
      "Data columns (total 90 columns):\n",
      " #   Column                          Non-Null Count     Dtype  \n",
      "---  ------                          --------------     -----  \n",
      " 0   id                              12083338 non-null  object \n",
      " 1   index                           12083338 non-null  int64  \n",
      " 2   period                          12083338 non-null  int64  \n",
      " 3   timestamp                       12083338 non-null  object \n",
      " 4   minute                          12083338 non-null  int64  \n",
      " 5   second                          12083338 non-null  int64  \n",
      " 6   possession                      12083338 non-null  int64  \n",
      " 7   duration                        8907451 non-null   float64\n",
      " 8   match_id                        12083338 non-null  int64  \n",
      " 9   type_id                         12083338 non-null  int64  \n",
      " 10  type_name                       12083338 non-null  object \n",
      " 11  possession_team_id              12083338 non-null  int64  \n",
      " 12  possession_team_name            12083338 non-null  object \n",
      " 13  play_pattern_id                 12083338 non-null  int64  \n",
      " 14  play_pattern_name               12083338 non-null  object \n",
      " 15  team_id                         12083338 non-null  int64  \n",
      " 16  team_name                       12083338 non-null  object \n",
      " 17  tactics_formation               15418 non-null     object \n",
      " 18  player_id                       12031877 non-null  float64\n",
      " 19  player_name                     12031877 non-null  object \n",
      " 20  position_id                     12031877 non-null  float64\n",
      " 21  position_name                   12031877 non-null  object \n",
      " 22  pass_recipient_id               3144369 non-null   float64\n",
      " 23  pass_recipient_name             3144369 non-null   object \n",
      " 24  pass_length                     3358652 non-null   float64\n",
      " 25  pass_angle                      3358652 non-null   float64\n",
      " 26  pass_height_id                  3358652 non-null   float64\n",
      " 27  pass_height_name                3358652 non-null   object \n",
      " 28  end_x                           6111477 non-null   float64\n",
      " 29  end_y                           6111477 non-null   float64\n",
      " 30  body_part_id                    3384757 non-null   float64\n",
      " 31  body_part_name                  3384757 non-null   object \n",
      " 32  sub_type_id                     1161001 non-null   float64\n",
      " 33  sub_type_name                   1161001 non-null   object \n",
      " 34  x                               11992626 non-null  float64\n",
      " 35  y                               11992626 non-null  float64\n",
      " 36  pass_switch                     94292 non-null     object \n",
      " 37  outcome_id                      1781615 non-null   float64\n",
      " 38  outcome_name                    1781615 non-null   object \n",
      " 39  under_pressure                  2524364 non-null   float64\n",
      " 40  aerial_won                      122820 non-null    object \n",
      " 41  counterpress                    389485 non-null    float64\n",
      " 42  off_camera                      161445 non-null    float64\n",
      " 43  ball_recovery_recovery_failure  27522 non-null     object \n",
      " 44  pass_assisted_shot_id           61394 non-null     object \n",
      " 45  pass_shot_assist                55110 non-null     object \n",
      " 46  shot_statsbomb_xg               87111 non-null     float64\n",
      " 47  end_z                           60905 non-null     float64\n",
      " 48  shot_key_pass_id                61394 non-null     object \n",
      " 49  shot_first_time                 26342 non-null     object \n",
      " 50  technique_id                    161218 non-null    float64\n",
      " 51  technique_name                  161218 non-null    object \n",
      " 52  goalkeeper_position_id          87238 non-null     float64\n",
      " 53  goalkeeper_position_name        87238 non-null     object \n",
      " 54  pass_cross                      79706 non-null     object \n",
      " 55  block_deflection                3679 non-null      object \n",
      " 56  dribble_nutmeg                  6681 non-null      object \n",
      " 57  foul_committed_offensive        3241 non-null      object \n",
      " 58  foul_committed_card_id          11513 non-null     float64\n",
      " 59  foul_committed_card_name        11513 non-null     object \n",
      " 60  foul_won_defensive              28211 non-null     object \n",
      " 61  out                             100267 non-null    float64\n",
      " 62  dribble_overrun                 7703 non-null      object \n",
      " 63  pass_miscommunication           1975 non-null      object \n",
      " 64  block_offensive                 2295 non-null      object \n",
      " 65  bad_behaviour_card_id           2520 non-null      float64\n",
      " 66  bad_behaviour_card_name         2520 non-null      object \n",
      " 67  substitution_replacement_id     21225 non-null     float64\n",
      " 68  substitution_replacement_name   21225 non-null     object \n",
      " 69  pass_cut_back                   6634 non-null      object \n",
      " 70  shot_one_on_one                 4632 non-null      object \n",
      " 71  foul_committed_advantage        11277 non-null     object \n",
      " 72  foul_won_advantage              11182 non-null     object \n",
      " 73  pass_deflected                  3493 non-null      object \n",
      " 74  pass_no_touch                   3043 non-null      object \n",
      " 75  pass_goal_assist                6284 non-null      object \n",
      " 76  foul_committed_penalty          971 non-null       object \n",
      " 77  foul_won_penalty                795 non-null       object \n",
      " 78  shot_deflected                  1140 non-null      object \n",
      " 79  block_save_block                555 non-null       object \n",
      " 80  ball_recovery_offensive         1139 non-null      object \n",
      " 81  shot_open_goal                  938 non-null       object \n",
      " 82  injury_stoppage_in_chain        1622 non-null      object \n",
      " 83  shot_follows_dribble            70 non-null        object \n",
      " 84  dribble_no_touch                466 non-null       object \n",
      " 85  half_start_late_video_start     92 non-null        object \n",
      " 86  pass_backheel                   723 non-null       object \n",
      " 87  shot_redirect                   204 non-null       object \n",
      " 88  player_off_permanent            38 non-null        object \n",
      " 89  half_end_early_video_end        10 non-null        object \n",
      "dtypes: float64(25), int64(10), object(55)\n",
      "memory usage: 8.2+ GB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_event = update(DATA_FOLDER, 'event', ids_to_update)\n",
    "        df_event.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n",
    "        df_event.to_parquet(os.path.join(DATA_FOLDER, 'event.parquet'))\n",
    "        df_event.info(verbose=True, show_counts=True)\n",
    "    else:\n",
    "        df_event = pd.concat([pd.read_parquet(file) for file in tqdm(event_files)])\n",
    "        df_event.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n",
    "        df_event.to_parquet(os.path.join(DATA_FOLDER, 'event.parquet'))\n",
    "        df_event.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single dataframe shot freeze frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [00:58<00:00, 58.98it/s]\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_29060\\294442557.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_freeze.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1110839 entries, 0 to 341\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   teammate         1110839 non-null  bool   \n",
      " 1   match_id         1110839 non-null  int64  \n",
      " 2   id               1110839 non-null  object \n",
      " 3   x                1110839 non-null  float64\n",
      " 4   y                1110839 non-null  float64\n",
      " 5   player_id        1110839 non-null  int64  \n",
      " 6   player_name      1110839 non-null  object \n",
      " 7   position_id      1110839 non-null  int64  \n",
      " 8   position_name    1110839 non-null  object \n",
      " 9   event_freeze_id  1110839 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(4), object(3)\n",
      "memory usage: 85.8+ MB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_freeze = update(DATA_FOLDER, 'freeze', ids_to_update)\n",
    "        df_freeze.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n",
    "        df_freeze.to_parquet(os.path.join(DATA_FOLDER, 'freeze.parquet'))\n",
    "        df_freeze.info(verbose=True, show_counts=True)\n",
    "    else:\n",
    "        freeze_files = glob.glob(os.path.join(DATA_FOLDER, 'freeze_raw', '*.parquet'))\n",
    "        df_freeze = pd.concat([pd.read_parquet(file) for file in tqdm(freeze_files)])\n",
    "        df_freeze.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n",
    "        df_freeze.to_parquet(os.path.join(DATA_FOLDER, 'freeze.parquet'))\n",
    "        df_freeze.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single dataframe tactics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [00:50<00:00, 68.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 169598 entries, 0 to 54\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   jersey_number     169598 non-null  int64 \n",
      " 1   match_id          169598 non-null  int64 \n",
      " 2   id                169598 non-null  object\n",
      " 3   player_id         169598 non-null  int64 \n",
      " 4   player_name       169598 non-null  object\n",
      " 5   position_id       169598 non-null  int64 \n",
      " 6   position_name     169598 non-null  object\n",
      " 7   event_tactics_id  169598 non-null  int64 \n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 11.6+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_29060\\1203663716.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_tactic.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_tactic = update(DATA_FOLDER, 'tactic', ids_to_update)\n",
    "        df_tactic.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n",
    "        df_tactic.to_parquet(os.path.join(DATA_FOLDER, 'tactic.parquet'))\n",
    "        df_tactic.info(verbose=True, show_counts=True)\n",
    "    else:\n",
    "        tactic_files = glob.glob(os.path.join(DATA_FOLDER, 'tactic_raw', '*.parquet'))\n",
    "        df_tactic = pd.concat([pd.read_parquet(file) for file in tqdm(tactic_files)])\n",
    "        df_tactic.player_id.replace(to_replace, inplace=True)  # replace some ids that appear to be split\n",
    "        df_tactic.to_parquet(os.path.join(DATA_FOLDER, 'tactic.parquet'))\n",
    "        df_tactic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single dataframe related events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3433/3433 [01:13<00:00, 46.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22969422 entries, 0 to 5232\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count     Dtype \n",
      "---  ------             --------------     ----- \n",
      " 0   match_id           22969422 non-null  int64 \n",
      " 1   id                 22969422 non-null  object\n",
      " 2   index              22969422 non-null  int64 \n",
      " 3   type_name          22969422 non-null  object\n",
      " 4   id_related         22969422 non-null  object\n",
      " 5   index_related      22969422 non-null  int64 \n",
      " 6   type_name_related  22969422 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_related = update(DATA_FOLDER, 'related', ids_to_update)\n",
    "        df_related.to_parquet(os.path.join(DATA_FOLDER, 'related.parquet'))\n",
    "        df_related.info(verbose=True, show_counts=True)\n",
    "    else:\n",
    "        related_files = glob.glob(os.path.join(DATA_FOLDER, 'related_raw', '*.parquet'))\n",
    "        df_related = pd.concat([pd.read_parquet(file) for file in tqdm(related_files)])\n",
    "        df_related.to_parquet(os.path.join(DATA_FOLDER, 'related.parquet'))\n",
    "        df_related.info(verbose=True, show_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expected-goals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
