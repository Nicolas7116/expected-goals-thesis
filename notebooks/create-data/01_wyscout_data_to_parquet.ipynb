{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the Wyscout data and turns them into parquet files. These are extremely fast to load so good for this prototyping kind of analysis.\n",
    "\n",
    "##### References:\n",
    "Pappalardo, Luca; Massucco, Emanuele (2019): Soccer match event dataset. figshare. Collection. https://doi.org/10.6084/m9.figshare.c.4415000\n",
    "\n",
    "Pappalardo, L., Cintia, P., Rossi, A. et al. A public data set of spatio-temporal match events in soccer competitions. Sci Data 6, 236 (2019). https://doi.org/10.1038/s41597-019-0247-7\n",
    "\n",
    "\n",
    "This updated code uses version 5 of this dataset: https://figshare.com/collections/Soccer_match_event_dataset/4415000/5\n",
    "\n",
    "The dataframes have the following number of entries:\n",
    "\n",
    "- df_coach: 208 entries\n",
    "- df_player: 3,603 entries\n",
    "- df_team: 142 entries\n",
    "- df_competition: 7 entries\n",
    "- df_match: 1,941 entries\n",
    "- df_formation: 74,098 entries\n",
    "- df_substitution: 11,097 entries\n",
    "- df_event: 3,251,294 entries\n",
    "\n",
    "The original code used version 2 of this dataset: https://figshare.com/collections/Soccer_match_event_dataset/4415000/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for wrangling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_location_cols(df, col, new_cols):\n",
    "    \"\"\" Location is stored as a list. split into columns. \"\"\"\n",
    "    for new_col in new_cols:\n",
    "        df[new_col] = np.nan\n",
    "    if col in df.columns:\n",
    "        mask_not_null = df[col].notnull()\n",
    "        df_not_null = df.loc[mask_not_null, col]\n",
    "        df_new = pd.DataFrame(df_not_null.tolist(), index=df_not_null.index)\n",
    "        new_cols = new_cols[:len(df_new.columns)]  # variable whether z location is present\n",
    "        df_new.columns = new_cols\n",
    "        df.loc[mask_not_null, new_cols] = df_new\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "def split_dict_col(df, col):\n",
    "    \"\"\" Function to split a dictionary column to separate columns.\"\"\"\n",
    "    # handle missing data by filling with an empty dictionary\n",
    "    df[col] = df[col].apply(lambda x: {} if pd.isna(x) else x)\n",
    "    # split the non-missing data and change the column names\n",
    "    df_temp_cols = pd.json_normalize(df[col]).set_index(df.index)\n",
    "    col_names = df_temp_cols.columns\n",
    "    # note add column description to column name if doesn't already contain it\n",
    "    col_names = [c.replace('.', '_') if c[:len(col)] == col else\n",
    "                 (col+'_'+c).replace('.', '_') for c in col_names]\n",
    "    df[col_names] = df_temp_cols\n",
    "    # drop old column\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def list_dictionary_to_df(df, col, value_name, var_name, id_col='id'):\n",
    "    \"\"\" Some columns are a list of dictionaries. This turns them into a new dataframe of rows.\"\"\"\n",
    "    df = df.loc[df[col].notnull(), [id_col, col]]\n",
    "    df.set_index(id_col, inplace=True)\n",
    "    df = df[col].apply(pd.Series).copy()\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.melt(id_vars=id_col, value_name=value_name, var_name=var_name)\n",
    "    df[var_name] = df[var_name] + 1\n",
    "    df = df[df[value_name].notnull()].copy()\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change these paths/ parameters\n",
    "You will need to change these paths/ parameters depending on where the StatsBomb open-data is located, how and where you want to save the resulting data, and if you only want the new files to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files in folder in current directory. To change if want to save elsewhere\n",
    "DATA_FOLDER = os.path.join('..', '..', 'data', 'wyscout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files that are jsons/csv\n",
    "COACHES_V5 = 'https://ndownloader.figshare.com/files/15073868'  # json\n",
    "REFEREES_V5 = 'https://ndownloader.figshare.com/files/15074030'  # json\n",
    "PLAYERS_V5 = 'https://ndownloader.figshare.com/files/15073721'  # json\n",
    "TEAMS_V5 = 'https://ndownloader.figshare.com/files/15073697'  # json\n",
    "COMPETITION_V5 = 'https://ndownloader.figshare.com/files/15073685'  # json\n",
    "EVENT_ID_MAPS_V5 = 'https://ndownloader.figshare.com/files/21385245'  # csv\n",
    "EVENT_TAG_MAPS_V5 = 'https://ndownloader.figshare.com/files/21385239'  # csv\n",
    "\n",
    "JSON_CSV_LINKS = [COACHES_V5, REFEREES_V5, PLAYERS_V5, TEAMS_V5, COMPETITION_V5, EVENT_ID_MAPS_V5, EVENT_TAG_MAPS_V5]\n",
    "JSON_CSV_FILES = ['coach.json', 'referees.json', 'player.json', 'team.json', 'competition.json',\n",
    "                  'eventid2name.csv', 'tags2name.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files that are zipped\n",
    "EVENTS_V5 = 'https://ndownloader.figshare.com/files/14464685'\n",
    "MATCHES_V5 = 'https://ndownloader.figshare.com/files/14464622'\n",
    "\n",
    "ZIP_LINKS = [EVENTS_V5, MATCHES_V5]\n",
    "ZIP_FILES = ['events.zip', 'matches.zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the directory structure\n",
    "for folder in ['raw', 'event_raw', 'match_raw', 'formation_raw', 'substitution_raw']:\n",
    "    path = os.path.join(DATA_FOLDER, folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128, json=False):\n",
    "    '''Souce: https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url '''\n",
    "    r = requests.get(url, stream=True)\n",
    "    if json:\n",
    "        r.encoding = 'unicode-escape'\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download json files\n",
    "for i, link in enumerate(JSON_CSV_LINKS):\n",
    "    download_url(link, os.path.join(DATA_FOLDER, 'raw', JSON_CSV_FILES[i]), json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zip files, extract jsons, and remove original zip files\n",
    "for i, link in enumerate(ZIP_LINKS):\n",
    "    save_path = os.path.join(DATA_FOLDER, 'raw', ZIP_FILES[i])\n",
    "    download_url(link, save_path)\n",
    "    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(DATA_FOLDER, 'raw'))\n",
    "    os.remove(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename dictionary for consistency with StatsBomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_rename = {'Real Club Celta de Vigo': 'Celta Vigo',\n",
    "               'Valencia Club de Fútbol': 'Valencia',\n",
    "               'FC Barcelona': 'Barcelona',\n",
    "               'Real Betis Balompié': 'Real Betis',\n",
    "               'Girona FC': 'Girona',\n",
    "               'CD Leganés': 'Leganés',\n",
    "               'Real Sociedad de Fútbol': 'Real Sociedad',\n",
    "               'Real Club Deportivo de La Coruña': 'Deportivo La Coruna',\n",
    "               'Sevilla FC': 'Sevilla',\n",
    "               'Getafe Club de Fútbol': 'Getafe',\n",
    "               'Athletic Club Bilbao': 'Athletic Club',\n",
    "               'Real Madrid Club de Fútbol': 'Real Madrid',\n",
    "               'Málaga Club de Fútbol': 'Málaga',\n",
    "               'Levante UD': 'Levante',\n",
    "               'Reial Club Deportiu Espanyol': 'Espanyol',\n",
    "               'UD Las Palmas': 'Las Palmas',\n",
    "               'SD Eibar': 'Eibar',\n",
    "               'Villarreal Club de Fútbol': 'Villarreal',\n",
    "               'Manchester United FC': 'Manchester United',\n",
    "               'Manchester City FC': 'Manchester City',\n",
    "               'Tottenham Hotspur FC': 'Tottenham Hotspur',\n",
    "               'AS Monaco FC': 'AS Monaco',\n",
    "               'Newcastle United FC': 'Newcastle United',\n",
    "               'Leicester City FC': 'Leicester City',\n",
    "               'Juventus FC': 'Juventus',\n",
    "               'BV Borussia 09 Dortmund': 'Borussia Dortmund',\n",
    "               'Everton FC': 'Everton',\n",
    "               'Arsenal FC': 'Arsenal',\n",
    "               'Southampton FC': 'Southampton',\n",
    "               'Liverpool FC': 'Liverpool',\n",
    "               'Chelsea FC': 'Chelsea',\n",
    "               'Club Atlético de Madrid': 'Atlético Madrid',\n",
    "               'Korea Republic': 'South Korea'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   coach_id                 208 non-null    int64 \n",
      " 1   shortName                208 non-null    object\n",
      " 2   firstName                208 non-null    object\n",
      " 3   middleName               208 non-null    object\n",
      " 4   lastName                 208 non-null    object\n",
      " 5   birthDate                206 non-null    object\n",
      " 6   currentTeamId            208 non-null    int64 \n",
      " 7   passportArea_id          208 non-null    int64 \n",
      " 8   passportArea_alpha2code  208 non-null    object\n",
      " 9   passportArea_alpha3code  208 non-null    object\n",
      " 10  passportArea_name        208 non-null    object\n",
      " 11  birthArea_id             208 non-null    int64 \n",
      " 12  birthArea_alpha2code     208 non-null    object\n",
      " 13  birthArea_alpha3code     208 non-null    object\n",
      " 14  birthArea_name           208 non-null    object\n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 24.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_coach = pd.read_json(os.path.join(DATA_FOLDER, 'raw', 'coach.json'), encoding='unicode-escape')\n",
    "for col in ['passportArea', 'birthArea']:\n",
    "    df_coach = split_dict_col(df_coach, col)\n",
    "df_coach.to_parquet(os.path.join(DATA_FOLDER, 'coach.parquet'))\n",
    "df_coach.rename({'wyId': 'coach_id'}, axis=1, inplace=True)\n",
    "df_coach.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3603 entries, 0 to 3602\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   weight                   3603 non-null   int64  \n",
      " 1   firstName                3603 non-null   object \n",
      " 2   middleName               3603 non-null   object \n",
      " 3   lastName                 3603 non-null   object \n",
      " 4   currentTeamId            3468 non-null   float32\n",
      " 5   birthDate                3603 non-null   object \n",
      " 6   height                   3603 non-null   int64  \n",
      " 7   player_id                3603 non-null   int64  \n",
      " 8   foot                     3603 non-null   object \n",
      " 9   shortName                3603 non-null   object \n",
      " 10  currentNationalTeamId    1357 non-null   float32\n",
      " 11  passportArea_name        3603 non-null   object \n",
      " 12  passportArea_id          3603 non-null   float32\n",
      " 13  passportArea_alpha3code  3603 non-null   object \n",
      " 14  passportArea_alpha2code  3603 non-null   object \n",
      " 15  role_code2               3603 non-null   object \n",
      " 16  role_code3               3603 non-null   object \n",
      " 17  role_name                3603 non-null   object \n",
      " 18  birthArea_name           3603 non-null   object \n",
      " 19  birthArea_id             3603 non-null   float32\n",
      " 20  birthArea_alpha3code     3603 non-null   object \n",
      " 21  birthArea_alpha2code     3603 non-null   object \n",
      "dtypes: float32(4), int64(3), object(15)\n",
      "memory usage: 563.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_player = pd.read_json(os.path.join(DATA_FOLDER, 'raw', 'player.json'), encoding='unicode-escape')\n",
    "for col in ['passportArea', 'role', 'birthArea']:\n",
    "    df_player = split_dict_col(df_player, col)\n",
    "# some of the ids are null some are 'null' as text :)\n",
    "for col in ['currentTeamId', 'currentNationalTeamId', 'passportArea_id', 'birthArea_id']:\n",
    "    mask_null = (df_player[col].isnull())|(df_player[col] == 'null')\n",
    "    df_player.loc[mask_null, col] = np.nan\n",
    "    df_player[col] = df_player[col].astype(np.float32)\n",
    "df_player.rename({'wyId': 'player_id'}, axis=1, inplace=True)\n",
    "df_player.to_parquet(os.path.join(DATA_FOLDER, 'player.parquet'))\n",
    "df_player.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142 entries, 0 to 141\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   city             142 non-null    object\n",
      " 1   name             142 non-null    object\n",
      " 2   team_id          142 non-null    int64 \n",
      " 3   officialName     142 non-null    object\n",
      " 4   type             142 non-null    object\n",
      " 5   area_name        142 non-null    object\n",
      " 6   area_id          142 non-null    int32 \n",
      " 7   area_alpha3code  142 non-null    object\n",
      " 8   area_alpha2code  142 non-null    object\n",
      "dtypes: int32(1), int64(1), object(7)\n",
      "memory usage: 9.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2902078870.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_team.officialName.replace(team_rename, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_team = pd.read_json(os.path.join(DATA_FOLDER, 'raw', 'team.json'), encoding='unicode-escape')\n",
    "df_team = split_dict_col(df_team, 'area')\n",
    "df_team['area_id'] = df_team.area_id.astype(np.int32)\n",
    "df_team.rename({'wyId': 'team_id'}, axis=1, inplace=True)\n",
    "df_team.officialName.replace(team_rename, inplace=True)\n",
    "df_team.to_parquet(os.path.join(DATA_FOLDER, 'team.parquet'))\n",
    "df_team.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   competition_name          7 non-null      object \n",
      " 1   competition_id            7 non-null      int64  \n",
      " 2   format                    7 non-null      object \n",
      " 3   type                      7 non-null      object \n",
      " 4   area_name                 7 non-null      object \n",
      " 5   area_id                   5 non-null      float32\n",
      " 6   area_alpha3code           7 non-null      object \n",
      " 7   area_alpha2code           7 non-null      object \n",
      " 8   competition_country_name  7 non-null      object \n",
      " 9   competition_gender        7 non-null      object \n",
      " 10  season_name               7 non-null      object \n",
      "dtypes: float32(1), int64(1), object(9)\n",
      "memory usage: 720.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\1691170309.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_competition.name.replace({'Spanish first division': 'La Liga',\n"
     ]
    }
   ],
   "source": [
    "df_competition = pd.read_json(os.path.join(DATA_FOLDER, 'raw', 'competition.json'), encoding='unicode-escape')\n",
    "df_competition = split_dict_col(df_competition, 'area')\n",
    "# if the area id is '0' as text for internationals set to missing\n",
    "df_competition.loc[df_competition.format=='International cup', 'area_id'] = np.nan\n",
    "df_competition['area_id'] = df_competition.area_id.astype(np.float32)\n",
    "# make same format as StatsBomb: competition_country_name\n",
    "mask = df_competition.type=='club'\n",
    "df_competition.loc[mask, 'competition_country_name'] = df_competition.loc[mask, 'area_name']\n",
    "mask = df_competition.type=='international'\n",
    "df_competition.loc[mask, 'competition_country_name'] = 'International'\n",
    "# add gender\n",
    "df_competition['competition_gender'] = 'male'\n",
    "# replace with competition real names\n",
    "df_competition.name.replace({'Spanish first division': 'La Liga',\n",
    "                             'World Cup': 'FIFA World Cup',\n",
    "                             'Italian first division': 'Serie A',\n",
    "                             'English first division': 'Premier League',\n",
    "                             'French first division': 'Ligue 1',\n",
    "                             'German first division': 'Bundesliga',\n",
    "                             'European Championship': 'UEFA Euro'}, inplace=True)\n",
    "# rename competition name\n",
    "df_competition.rename({'name': 'competition_name', 'wyId': 'competition_id'}, axis=1, inplace=True)\n",
    "# add season name\n",
    "df_competition.loc[df_competition.type == 'club', 'season_name'] = '2017/2018'\n",
    "df_competition.loc[df_competition.competition_name == 'UEFA Euro', 'season_name'] = '2016'\n",
    "df_competition.loc[df_competition.competition_name == 'FIFA World Cup', 'season_name'] = '2018'\n",
    "df_competition.to_parquet(os.path.join(DATA_FOLDER, 'competition.parquet'))\n",
    "df_competition.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:46: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:46: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:46: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:46: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:46: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.home_team_name.replace(team_rename, inplace=True)\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\3367373186.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_match.away_team_name.replace(team_rename, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# list of match files\n",
    "match_list = glob.glob(os.path.join(DATA_FOLDER, 'raw', 'matches*.json'))\n",
    "\n",
    "# loop through match files as save as seperate parquet files\n",
    "for file in match_list:\n",
    "    \n",
    "    # match dataframe\n",
    "    df_match = pd.read_json(file, encoding='unicode-escape')\n",
    "    \n",
    "    # split the team information from the teamsData column into two seperate columns\n",
    "    col = 'teamsData'\n",
    "    df_match[col] = df_match[col].apply(lambda x: {} if pd.isna(x) else x)\n",
    "    df_match['team1'] = df_match.teamsData.apply(lambda x: x[list(x.keys())[0]])\n",
    "    df_match['team2'] = df_match.teamsData.apply(lambda x: x[list(x.keys())[1]])\n",
    "    \n",
    "    # split team information stored as a dictionary into seperate columns\n",
    "    df_match = split_dict_col(df_match, 'team1')\n",
    "    df_match = split_dict_col(df_match, 'team2')\n",
    "    \n",
    "    # add home and away teams and scores up to extra time\n",
    "    mask = df_match.team1_side == 'home'\n",
    "    mask_et = (df_match.team1_scoreET > 0) | (df_match.team2_scoreET > 0)\n",
    "    df_match.loc[mask,'home_score'] = df_match.loc[mask,'team1_score']\n",
    "    df_match.loc[mask,'away_score'] = df_match.loc[mask,'team2_score']\n",
    "    df_match.loc[~mask,'home_score'] = df_match.loc[~mask,'team2_score']\n",
    "    df_match.loc[~mask,'away_score'] = df_match.loc[~mask,'team1_score']\n",
    "    df_match.loc[mask_et & mask,'home_score'] = df_match.loc[mask_et & mask,'team1_scoreET']\n",
    "    df_match.loc[mask_et & mask,'away_score'] = df_match.loc[mask_et & mask,'team2_scoreET']\n",
    "    df_match.loc[mask_et & ~mask,'home_score'] = df_match.loc[mask_et & ~mask,'team2_scoreET']\n",
    "    df_match.loc[mask_et & ~mask,'away_score'] = df_match.loc[mask_et & ~mask,'team1_scoreET']    \n",
    "    \n",
    "    # add away/ home team info\n",
    "    df_match.loc[mask, 'home_team_id'] = df_match.loc[mask, 'team1_teamId']\n",
    "    df_match.loc[~mask, 'home_team_id'] = df_match.loc[~mask, 'team2_teamId']\n",
    "    df_match.loc[mask, 'away_team_id'] = df_match.loc[mask, 'team2_teamId']\n",
    "    df_match.loc[~mask, 'away_team_id'] = df_match.loc[~mask, 'team1_teamId']\n",
    "    \n",
    "    # add away/home coach info\n",
    "    df_match.loc[mask, 'home_team_coach_id'] = df_match.loc[mask, 'team1_coachId']\n",
    "    df_match.loc[~mask, 'home_team_coach_id'] = df_match.loc[~mask, 'team2_coachId']\n",
    "    df_match.loc[mask, 'away_team_coach_id'] = df_match.loc[mask, 'team2_coachId']\n",
    "    df_match.loc[~mask, 'away_team_coach_id'] = df_match.loc[~mask, 'team1_coachId']\n",
    "\n",
    "    # format date columns\n",
    "    df_match['dateutc'] = pd.to_datetime(df_match.dateutc)\n",
    "    df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
    "    \n",
    "    # rename columns\n",
    "    df_match.rename({'wyId': 'match_id',\n",
    "                     'gameweek': 'match_week',\n",
    "                     'seasonId': 'season_id',\n",
    "                     'competitionId': 'competition_id',\n",
    "                     'venue': 'stadium_name'}, axis=1, inplace=True)\n",
    "    \n",
    "    # add competition info\n",
    "    df_match = df_match.merge(df_competition[['competition_id',\n",
    "                                              'competition_country_name',\n",
    "                                              'competition_name',\n",
    "                                              'season_name',\n",
    "                                              'competition_gender']], on='competition_id', how='left')\n",
    "    \n",
    "    # add team info\n",
    "    df_match = df_match.merge(df_team[['team_id', 'officialName']],\n",
    "                              left_on='home_team_id', right_on='team_id', how='left')\n",
    "    df_match = df_match.merge(df_team[['team_id', 'officialName']],\n",
    "                              left_on='away_team_id', right_on='team_id', how='left', suffixes=['_home', '_away'])\n",
    "    \n",
    "    df_match.rename({'officialName_home': 'home_team_name',\n",
    "                     'officialName_away': 'away_team_name'}, axis=1, inplace=True)\n",
    "    \n",
    "    # replace some team names to be the same as StatsBomb\n",
    "    df_match.home_team_name.replace(team_rename, inplace=True)\n",
    "    df_match.away_team_name.replace(team_rename, inplace=True)\n",
    "\n",
    "    # dataframes with the team id for adding to the formation/ substitutions\n",
    "    df_team1 = df_match[['match_id', 'team1_teamId']].rename({'team1_teamId': 'team_id'}, axis=1)\n",
    "    df_team2 = df_match[['match_id', 'team2_teamId']].rename({'team2_teamId': 'team_id'}, axis=1)\n",
    "    \n",
    "    # formation lineup dataframe\n",
    "    df_team1_formation_lineup = list_dictionary_to_df(df_match, 'team1_formation_lineup', 'lineup',\n",
    "                                                      'lineup_id', 'match_id')\n",
    "    df_team2_formation_lineup = list_dictionary_to_df(df_match, 'team2_formation_lineup', 'lineup',\n",
    "                                                      'lineup_id', 'match_id')\n",
    "    df_team1_formation_lineup = df_team1_formation_lineup.merge(df_team1, on='match_id', how='left')\n",
    "    df_team2_formation_lineup = df_team2_formation_lineup.merge(df_team2, on='match_id', how='left')\n",
    "    df_formation_lineup = pd.concat([df_team1_formation_lineup, df_team2_formation_lineup])\n",
    "    df_formation_lineup = split_dict_col(df_formation_lineup, 'lineup')\n",
    "    df_formation_lineup['bench'] = False\n",
    "    \n",
    "    # formation bench lineup\n",
    "    df_team1_formation_bench = list_dictionary_to_df(df_match, 'team1_formation_bench', 'lineup',\n",
    "                                                     'lineup_id', 'match_id')\n",
    "    df_team2_formation_bench = list_dictionary_to_df(df_match, 'team2_formation_bench', 'lineup',\n",
    "                                                     'lineup_id', 'match_id')\n",
    "    df_team1_formation_bench = df_team1_formation_bench.merge(df_team1, on='match_id', how='left')\n",
    "    df_team2_formation_bench = df_team2_formation_bench.merge(df_team2, on='match_id', how='left')\n",
    "    df_formation_bench = pd.concat([df_team1_formation_bench, df_team2_formation_bench])\n",
    "    df_formation_bench = split_dict_col(df_formation_bench, 'lineup')\n",
    "    df_formation_bench['bench'] = True\n",
    "    \n",
    "    # combine lineup from bench/ not from bench\n",
    "    df_formation = pd.concat([df_formation_lineup, df_formation_bench])\n",
    "        \n",
    "    df_formation.rename({'lineup_playerId': 'player_id', 'lineup_ownGoals': 'ownGoals',\n",
    "                         'lineup_redCards': 'redCards', 'lineup_goals': 'goals', 'lineup_yellowCards': 'yellowCards'},\n",
    "                        axis=1, inplace=True)\n",
    "    \n",
    "    # fix an error where the goalkeeper (Hitz) isn't starting (Jakob is in error): Borussia Dortmund vs Augsburg 2018-02-26\n",
    "    df_formation.loc[(df_formation.match_id == 2516947) & (df_formation.player_id == 14914), 'bench'] = False\n",
    "    df_formation.loc[(df_formation.match_id == 2516947) & (df_formation.player_id == 391449), 'bench'] = True\n",
    "    \n",
    "    # get a subsitutions dataframe\n",
    "    df_team1_formation_substitutions = list_dictionary_to_df(df_match, 'team1_formation_substitutions',\n",
    "                                                              'lineup', 'sub_id', 'match_id')\n",
    "    df_team2_formation_substitutions = list_dictionary_to_df(df_match, 'team2_formation_substitutions', \n",
    "                                                              'lineup', 'sub_id', 'match_id')\n",
    "    df_team1_formation_substitutions = df_team1_formation_substitutions.merge(df_team1, on='match_id', how='left')\n",
    "    df_team2_formation_substitutions = df_team2_formation_substitutions.merge(df_team2, on='match_id', how='left')\n",
    "    df_formation_substitutions = pd.concat([df_team1_formation_substitutions, df_team2_formation_substitutions])\n",
    "    df_formation_substitutions = df_formation_substitutions[df_formation_substitutions.lineup != 'null'].copy()\n",
    "    df_formation_substitutions = split_dict_col(df_formation_substitutions, 'lineup')\n",
    "    df_formation_substitutions.rename({'id': 'match_id', 'lineup_playerIn': 'player_id_in',\n",
    "                                       'lineup_playerOut': 'player_id_out', 'lineup_minute': 'minute'},\n",
    "                                      axis=1, inplace=True)\n",
    "    \n",
    "    # drop columns\n",
    "    df_match.drop(['date', 'status', 'winner', 'referees', 'team_id_away', 'team_id_home',\n",
    "                   'team1_formation_bench', 'team1_formation_lineup', 'team1_formation_substitutions',\n",
    "                   'team2_formation_bench', 'team2_formation_lineup', 'team2_formation_substitutions',\n",
    "                   'team1_hasFormation', 'team2_hasFormation',\n",
    "                   'team1_score', 'team1_scoreP', 'team1_scoreHT', 'team1_scoreET',\n",
    "                   'team2_score', 'team2_scoreP', 'team2_scoreHT', 'team2_scoreET',\n",
    "                   'teamsData', 'team1_teamId', 'team2_teamId', 'team2_side',\n",
    "                   'team1_side', 'team1_coachId', 'team2_coachId'], axis=1, inplace=True)\n",
    "    \n",
    "    save_path = os.path.join(DATA_FOLDER, 'match_raw', f'{os.path.basename(file)[:-4]}parquet')\n",
    "    df_match.to_parquet(save_path)\n",
    "    \n",
    "    save_path = os.path.join(DATA_FOLDER, 'formation_raw', f'{os.path.basename(file)[:-4]}parquet')\n",
    "    df_formation.to_parquet(save_path)\n",
    "    \n",
    "    save_path = os.path.join(DATA_FOLDER, 'substitution_raw', f'{os.path.basename(file)[:-4]}parquet')\n",
    "    df_formation_substitutions.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get matches as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1941 entries, 0 to 63\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   roundId                   1941 non-null   int64         \n",
      " 1   match_week                1941 non-null   int64         \n",
      " 2   season_id                 1941 non-null   int64         \n",
      " 3   dateutc                   1941 non-null   datetime64[ns]\n",
      " 4   stadium_name              1941 non-null   object        \n",
      " 5   match_id                  1941 non-null   int64         \n",
      " 6   label                     1941 non-null   object        \n",
      " 7   duration                  1941 non-null   object        \n",
      " 8   competition_id            1941 non-null   int64         \n",
      " 9   home_score                1941 non-null   float64       \n",
      " 10  away_score                1941 non-null   float64       \n",
      " 11  home_team_id              1941 non-null   float64       \n",
      " 12  away_team_id              1941 non-null   float64       \n",
      " 13  home_team_coach_id        1941 non-null   float64       \n",
      " 14  away_team_coach_id        1941 non-null   float64       \n",
      " 15  kick_off                  1941 non-null   datetime64[ns]\n",
      " 16  competition_country_name  1941 non-null   object        \n",
      " 17  competition_name          1941 non-null   object        \n",
      " 18  season_name               1941 non-null   object        \n",
      " 19  competition_gender        1941 non-null   object        \n",
      " 20  home_team_name            1941 non-null   object        \n",
      " 21  away_team_name            1941 non-null   object        \n",
      " 22  groupName                 115 non-null    object        \n",
      "dtypes: datetime64[ns](2), float64(6), int64(5), object(10)\n",
      "memory usage: 363.9+ KB\n"
     ]
    }
   ],
   "source": [
    "match_files = glob.glob(os.path.join(DATA_FOLDER, 'match_raw', '*.parquet'))\n",
    "df_match = pd.concat([pd.read_parquet(file) for file in match_files])\n",
    "df_match.to_parquet(os.path.join(DATA_FOLDER, 'match.parquet'))\n",
    "df_match.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the formation as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 74098 entries, 0 to 738\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   match_id        74098 non-null  int64 \n",
      " 1   lineup_id       74098 non-null  int64 \n",
      " 2   team_id         74098 non-null  int64 \n",
      " 3   player_id       74098 non-null  int64 \n",
      " 4   ownGoals        74098 non-null  object\n",
      " 5   redCards        74098 non-null  object\n",
      " 6   goals           74098 non-null  object\n",
      " 7   yellowCards     74098 non-null  object\n",
      " 8   bench           74098 non-null  bool  \n",
      " 9   lineup_assists  5211 non-null   object\n",
      "dtypes: bool(1), int64(4), object(5)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(os.path.join(DATA_FOLDER, 'formation_raw', '*.parquet'))\n",
    "df_formation = pd.concat([pd.read_parquet(file) for file in files])\n",
    "df_formation.to_parquet(os.path.join(DATA_FOLDER, 'formation.parquet'))\n",
    "df_formation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the substitution as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11097 entries, 0 to 188\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   match_id        11097 non-null  int64 \n",
      " 1   sub_id          11097 non-null  int64 \n",
      " 2   team_id         11097 non-null  int64 \n",
      " 3   player_id_in    11097 non-null  int64 \n",
      " 4   player_id_out   11097 non-null  int64 \n",
      " 5   minute          11097 non-null  int64 \n",
      " 6   lineup_assists  674 non-null    object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 693.6+ KB\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(os.path.join(DATA_FOLDER, 'substitution_raw', '*.parquet'))\n",
    "df_substitution = pd.concat([pd.read_parquet(file) for file in files])\n",
    "df_substitution.to_parquet(os.path.join(DATA_FOLDER, 'substitution.parquet'))\n",
    "df_substitution.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dataframe with the tag description/ arrays with tag types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tag = pd.read_csv(os.path.join(DATA_FOLDER, 'raw', 'tags2name.csv'))\n",
    "df_tag['Description'] = df_tag.Description.str.lower().str.replace(':', '').str.replace(' ', '_').str.replace('/', '_')\n",
    "position_tags = df_tag.loc[df_tag.Description.str[:8] == 'position', 'Tag'].values\n",
    "other_tags = df_tag.loc[df_tag.Description.str[:8] != 'position', 'Description'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through event files and save as parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_England.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 49, 'x': 49} {'y': 78, 'x': 31} {'y': 75, 'x': 51} ...\n",
      " {'y': 53, 'x': 12} {'y': 47, 'x': 88} {'y': 50, 'x': 86}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 78, 'x': 31} {'y': 75, 'x': 51} {'y': 71, 'x': 35} ...\n",
      " {'y': 50, 'x': 14} {'y': 50, 'x': 86} {'y': 0, 'x': 0}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_European_Championship.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 48, 'x': 50} {'y': 50, 'x': 47} {'y': 48, 'x': 41} ...\n",
      " {'y': 63, 'x': 9} {'y': 78, 'x': 67} {'y': 22, 'x': 33}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 50, 'x': 47} {'y': 48, 'x': 41} {'y': 35, 'x': 32} ...\n",
      " {'y': 78, 'x': 67} {'y': 0, 'x': 0} {'y': 100, 'x': 100}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_France.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 51, 'x': 50} {'y': 46, 'x': 31} {'y': 74, 'x': 68} ...\n",
      " {'y': 52, 'x': 50} {'y': 47, 'x': 44} {'y': 8, 'x': 41}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 46, 'x': 31} {'y': 74, 'x': 68} {'y': 54, 'x': 72} ...\n",
      " {'y': 47, 'x': 44} {'y': 8, 'x': 41} {'y': 0, 'x': 0}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_Germany.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 50, 'x': 50} {'y': 48, 'x': 50} {'y': 22, 'x': 22} ...\n",
      " {'y': 6, 'x': 90} {'y': 95, 'x': 0} {'y': 7, 'x': 95}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 48, 'x': 50} {'y': 22, 'x': 22} {'y': 46, 'x': 6} ...\n",
      " {'y': 5, 'x': 100} {'y': 93, 'x': 5} {'y': 100, 'x': 100}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_Italy.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 52, 'x': 49} {'y': 44, 'x': 43} {'y': 17, 'x': 36} ...\n",
      " {'y': 65, 'x': 95} {'y': 36, 'x': 3} {'y': 64, 'x': 97}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 44, 'x': 43} {'y': 17, 'x': 36} {'y': 56, 'x': 78} ...\n",
      " {'y': 64, 'x': 97} {'y': 100, 'x': 100} {'y': 0, 'x': 0}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_Spain.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 61, 'x': 37} {'y': 50, 'x': 50} {'y': 30, 'x': 45} ...\n",
      " {'y': 21, 'x': 97} {'y': 74, 'x': 8} {'y': 56, 'x': 9}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 50, 'x': 50} {'y': 30, 'x': 45} {'y': 12, 'x': 38} ...\n",
      " {'y': 26, 'x': 92} {'y': 56, 'x': 9} {'y': 100, 'x': 100}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_World_Cup.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 50, 'x': 50} {'y': 53, 'x': 35} {'y': 81, 'x': 25} ...\n",
      " {'y': 2, 'x': 82} {'y': 0, 'x': 0} {'y': 43, 'x': 14}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\390497779.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[{'y': 53, 'x': 35} {'y': 19, 'x': 75} {'y': 83, 'x': 37} ...\n",
      " {'y': 100, 'x': 100} {'y': 98, 'x': 18} {'y': 0, 'x': 0}]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask_not_null, new_cols] = df_new\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_2744\\2833330164.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n"
     ]
    }
   ],
   "source": [
    "# list of event files\n",
    "events_list = glob.glob(os.path.join(DATA_FOLDER, 'raw', 'events*.json'))\n",
    "\n",
    "# loop through event files as save as seperate parquet files\n",
    "for file in events_list:\n",
    "    \n",
    "    print(os.path.basename(file))\n",
    "    \n",
    "    # load as dataframe\n",
    "    df_event = pd.read_json(file, encoding='unicode-escape')\n",
    "    \n",
    "    # split start and end positions\n",
    "    split_location_cols(df_event, 'positions', ['start', 'end'])\n",
    "    \n",
    "    # create seperate columns for the x/y coordinates\n",
    "    for col in ['start', 'end']:\n",
    "        df_event = split_dict_col(df_event, col)\n",
    "        \n",
    "    # set dodgy end coordinates to null\n",
    "    mask = df_event.eventName.isin(['Shot', 'Interruption', 'Offside'])\n",
    "    mask2 = df_event.subEventName.isin(['Free kick shot', 'Hand foul', 'Late card foul',\n",
    "                                        'Out of game foul', 'Protest',\n",
    "                                        'Simulation', 'Time lost foul', 'Violent Foul'])\n",
    "    df_event.loc[mask | mask2, 'end_x'] = np.nan\n",
    "    df_event.loc[mask | mask2, 'end_y'] = np.nan\n",
    "    \n",
    "    # wyscout has some dodgy end_y/ end_x near the corners. Convert to np.nan\n",
    "    mask_dodgy_end = (((df_event.end_y == 100) & (df_event.end_x == 100)) | \n",
    "                      ((df_event.end_x == 0) & (df_event.end_y == 0)))\n",
    "    df_event.loc[mask_dodgy_end, 'end_y'] = np.nan\n",
    "    df_event.loc[mask_dodgy_end, 'end_x'] = np.nan\n",
    "    \n",
    "    # set dodgy start coordinates to null\n",
    "    df_event.loc[df_event.eventName.isin(['Save attempt', 'Goalkeeper leaving line']), 'start_x'] = np.nan\n",
    "    df_event.loc[df_event.eventName.isin(['Save attempt', 'Goalkeeper leaving line']), 'start_y'] = np.nan\n",
    "    \n",
    "    # fix start coordinates for goal kicks\n",
    "    df_event.loc[df_event.subEventName == 'Goal kick', 'start_x'] = 6.\n",
    "    df_event.loc[df_event.subEventName == 'Goal kick', 'start_y'] = 50.\n",
    "    \n",
    "    # create a seperate column for each tag in the dictionary\n",
    "    df_new = pd.DataFrame(df_event['tags'].tolist(), index=df_event.index)\n",
    "    for tag in df_new.columns:\n",
    "        df_new.loc[df_new[tag].notnull(), tag] = df_new.loc[df_new[tag].notnull(), tag].apply(lambda x: x['id'])\n",
    "        \n",
    "    # summarise tag id columns into boolean columns for each tag and a string column for position \n",
    "    cols_to_drop = df_new.columns\n",
    "    for i, row in df_tag.iterrows():\n",
    "        if row['Tag'] not in position_tags:\n",
    "            df_new.loc[(df_new == row['Tag']).any(axis=1), row['Description']] = True\n",
    "        else:\n",
    "            df_new.loc[(df_new == row['Tag']).any(axis=1), 'position'] = row['Description']\n",
    "            \n",
    "    # remove 'position' and '_' from text in the position column\n",
    "    df_new['position'] = df_new.position.str[9:].str.replace('_', ' ')\n",
    "    df_new.loc[df_new['position'].isnull(), 'position'] = None\n",
    "    \n",
    "    # replace missing with False for boolean columns\n",
    "    df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n",
    "    \n",
    "    # drop tag id columns\n",
    "    df_new.drop(cols_to_drop, axis=1, inplace=True)                                               \n",
    "                                        \n",
    "    # add tags to the dataset\n",
    "    df_event = pd.concat([df_event, df_new], axis=1)\n",
    "    \n",
    "    # drop tag column\n",
    "    df_event.drop('tags', axis=1, inplace=True)\n",
    "    \n",
    "    # deal with blank subEventId\n",
    "    df_event.loc[df_event.subEventId=='', 'subEventId'] = None\n",
    "    df_event['subEventId'] = df_event['subEventId'].astype(np.float32)\n",
    "    \n",
    "    # rename columns for consistency with other datasets\n",
    "    df_event.rename({'playerId': 'player_id',\n",
    "                     'start_y': 'y',\n",
    "                     'start_x': 'x',\n",
    "                     'matchId': 'match_id',\n",
    "                     'teamId': 'team_id',}, axis=1, inplace=True)\n",
    "    \n",
    "    # save to parquet\n",
    "    save_path = os.path.join(DATA_FOLDER, 'event_raw', f'{os.path.basename(file)[:-4]}parquet')\n",
    "    df_event.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get events as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3251294 entries, 0 to 647371\n",
      "Data columns (total 51 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   eventId              3251294 non-null  int64  \n",
      " 1   subEventName         3251294 non-null  object \n",
      " 2   player_id            3251294 non-null  int64  \n",
      " 3   match_id             3251294 non-null  int64  \n",
      " 4   eventName            3251294 non-null  object \n",
      " 5   team_id              3251294 non-null  int64  \n",
      " 6   matchPeriod          3251294 non-null  object \n",
      " 7   eventSec             3251294 non-null  float64\n",
      " 8   subEventId           3243112 non-null  float32\n",
      " 9   id                   3251294 non-null  int64  \n",
      " 10  y                    3227510 non-null  float64\n",
      " 11  x                    3227510 non-null  float64\n",
      " 12  end_y                3024965 non-null  float64\n",
      " 13  end_x                3024965 non-null  float64\n",
      " 14  goal                 3251294 non-null  bool   \n",
      " 15  own_goal             3251294 non-null  bool   \n",
      " 16  assist               3251294 non-null  bool   \n",
      " 17  key_pass             3251294 non-null  bool   \n",
      " 18  counter_attack       3251294 non-null  bool   \n",
      " 19  left_foot            3251294 non-null  bool   \n",
      " 20  right_foot           3251294 non-null  bool   \n",
      " 21  head_body            3251294 non-null  bool   \n",
      " 22  direct               3251294 non-null  bool   \n",
      " 23  indirect             3251294 non-null  bool   \n",
      " 24  dangerous_ball_lost  3251294 non-null  bool   \n",
      " 25  blocked              3251294 non-null  bool   \n",
      " 26  high                 3251294 non-null  bool   \n",
      " 27  low                  3251294 non-null  bool   \n",
      " 28  interception         3251294 non-null  bool   \n",
      " 29  clearance            3251294 non-null  bool   \n",
      " 30  opportunity          3251294 non-null  bool   \n",
      " 31  feint                3251294 non-null  bool   \n",
      " 32  missed_ball          3251294 non-null  bool   \n",
      " 33  free_space_right     3251294 non-null  bool   \n",
      " 34  free_space_left      3251294 non-null  bool   \n",
      " 35  take_on_left         3251294 non-null  bool   \n",
      " 36  take_on_right        3251294 non-null  bool   \n",
      " 37  sliding_tackle       3251294 non-null  bool   \n",
      " 38  anticipated          3251294 non-null  bool   \n",
      " 39  anticipation         3251294 non-null  bool   \n",
      " 40  red_card             3251294 non-null  bool   \n",
      " 41  yellow_card          3251294 non-null  bool   \n",
      " 42  second_yellow_card   3251294 non-null  bool   \n",
      " 43  position             51618 non-null    object \n",
      " 44  through              3251294 non-null  bool   \n",
      " 45  fairplay             3251294 non-null  bool   \n",
      " 46  lost                 3251294 non-null  bool   \n",
      " 47  neutral              3251294 non-null  bool   \n",
      " 48  won                  3251294 non-null  bool   \n",
      " 49  accurate             3251294 non-null  bool   \n",
      " 50  not_accurate         3251294 non-null  bool   \n",
      "dtypes: bool(36), float32(1), float64(5), int64(5), object(4)\n",
      "memory usage: 496.1+ MB\n"
     ]
    }
   ],
   "source": [
    "event_files = glob.glob(os.path.join(DATA_FOLDER, 'event_raw', '*.parquet'))\n",
    "df_event = pd.concat([pd.read_parquet(file) for file in event_files])\n",
    "df_event.sort_values(['match_id', 'matchPeriod', 'eventSec'], inplace=True)\n",
    "df_event.to_parquet(os.path.join(DATA_FOLDER, 'event.parquet'))\n",
    "df_event.info(verbose=True, show_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expected-goals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
