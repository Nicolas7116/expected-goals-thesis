{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the Wyscout data and turns them into parquet files. These are extremely fast to load so good for this prototyping kind of analysis.\n",
    "\n",
    "##### References:\n",
    "Pappalardo, Luca; Massucco, Emanuele (2019): Soccer match event dataset. figshare. Collection. https://doi.org/10.6084/m9.figshare.c.4415000\n",
    "\n",
    "Pappalardo, L., Cintia, P., Rossi, A. et al. A public data set of spatio-temporal match events in soccer competitions. Sci Data 6, 236 (2019). https://doi.org/10.1038/s41597-019-0247-7\n",
    "\n",
    "Data link: https://figshare.com/collections/Soccer_match_event_dataset/4415000/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from mplsoccer.statsbomb import _split_location_cols, _split_dict_col, _list_dictionary_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change these paths/ parameters\n",
    "You will need to change these paths/ parameters depending on where the StatsBomb open-data is located, how and where you want to save the resulting data, and if you only want the new files to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files in folder in current directory. To change if want to save elsewhere\n",
    "DATA_FOLDER = os.path.join('..', '..', 'data', 'wyscout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files that are jsons\n",
    "JSON_LINKS = ['https://ndownloader.figshare.com/files/15073868',  # coaches\n",
    "              # 'https://ndownloader.figshare.com/files/15074030',  # referees <- not downloaded as corrupt\n",
    "              'https://ndownloader.figshare.com/files/15073721',  # players\n",
    "              'https://ndownloader.figshare.com/files/15073697',  # teams\n",
    "              'https://ndownloader.figshare.com/files/15073685',  # competitions\n",
    "              'https://raw.githubusercontent.com/andrewRowlinson/mplsoccer/master/wyscout_event_tags.json',  # my decode tags\n",
    "              ]  # competitions\n",
    "JSON_FILES = ['coach.json', \n",
    "              #'referees.json',  # <- not downloaded as corrupt\n",
    "              'player.json', 'team.json', 'competition.json',\n",
    "              'event_tag.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files that are zipped\n",
    "ZIP_LINKS = ['https://ndownloader.figshare.com/files/14464685',  # events\n",
    "             'https://ndownloader.figshare.com/files/14464622']  # matches\n",
    "ZIP_FILES = ['events.zip', 'matches.zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the directory structure\n",
    "for folder in ['json', 'event_raw', 'match_raw']:\n",
    "    path = os.path.join(DATA_FOLDER, folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128, json=False):\n",
    "    '''Souce: https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url '''\n",
    "    r = requests.get(url, stream=True)\n",
    "    if json:\n",
    "        r.encoding = 'unicode-escape'\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download json files\n",
    "for i, link in enumerate(JSON_LINKS):\n",
    "    download_url(link, os.path.join(DATA_FOLDER, 'json', JSON_FILES[i]), json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zip files, extract jsons, and remove original zip files\n",
    "for i, link in enumerate(ZIP_LINKS):\n",
    "    save_path = os.path.join(DATA_FOLDER, 'json', ZIP_FILES[i])\n",
    "    download_url(link, save_path)\n",
    "    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(DATA_FOLDER, 'json'))\n",
    "    os.remove(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   coach_id                 208 non-null    int64 \n",
      " 1   shortName                208 non-null    object\n",
      " 2   firstName                208 non-null    object\n",
      " 3   middleName               208 non-null    object\n",
      " 4   lastName                 208 non-null    object\n",
      " 5   birthDate                206 non-null    object\n",
      " 6   currentTeamId            208 non-null    int64 \n",
      " 7   passportArea_id          208 non-null    int64 \n",
      " 8   passportArea_alpha2code  208 non-null    object\n",
      " 9   passportArea_alpha3code  208 non-null    object\n",
      " 10  passportArea_name        208 non-null    object\n",
      " 11  birthArea_id             208 non-null    int64 \n",
      " 12  birthArea_alpha2code     208 non-null    object\n",
      " 13  birthArea_alpha3code     208 non-null    object\n",
      " 14  birthArea_name           208 non-null    object\n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 24.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_coach = pd.read_json(os.path.join(DATA_FOLDER, 'json', 'coach.json'), encoding='unicode-escape')\n",
    "for col in ['passportArea', 'birthArea']:\n",
    "    df_coach = _split_dict_col(df_coach, col)\n",
    "df_coach.to_parquet(os.path.join(DATA_FOLDER, 'coach.parquet'))\n",
    "df_coach.rename({'wyId': 'coach_id'}, axis=1, inplace=True)\n",
    "df_coach.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3603 entries, 0 to 3602\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   weight                   3603 non-null   int64  \n",
      " 1   firstName                3603 non-null   object \n",
      " 2   middleName               3603 non-null   object \n",
      " 3   lastName                 3603 non-null   object \n",
      " 4   currentTeamId            3468 non-null   float32\n",
      " 5   birthDate                3603 non-null   object \n",
      " 6   height                   3603 non-null   int64  \n",
      " 7   player_id                3603 non-null   int64  \n",
      " 8   foot                     3603 non-null   object \n",
      " 9   shortName                3603 non-null   object \n",
      " 10  currentNationalTeamId    1357 non-null   float32\n",
      " 11  passportArea_name        3603 non-null   object \n",
      " 12  passportArea_id          3603 non-null   float32\n",
      " 13  passportArea_alpha3code  3603 non-null   object \n",
      " 14  passportArea_alpha2code  3603 non-null   object \n",
      " 15  role_code2               3603 non-null   object \n",
      " 16  role_code3               3603 non-null   object \n",
      " 17  role_name                3603 non-null   object \n",
      " 18  birthArea_name           3603 non-null   object \n",
      " 19  birthArea_id             3603 non-null   float32\n",
      " 20  birthArea_alpha3code     3603 non-null   object \n",
      " 21  birthArea_alpha2code     3603 non-null   object \n",
      "dtypes: float32(4), int64(3), object(15)\n",
      "memory usage: 563.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_player = pd.read_json(os.path.join(DATA_FOLDER, 'json', 'player.json'), encoding='unicode-escape')\n",
    "for col in ['passportArea', 'role', 'birthArea']:\n",
    "    df_player = _split_dict_col(df_player, col)\n",
    "# some of the ids are null some are 'null' as text :)\n",
    "for col in ['currentTeamId', 'currentNationalTeamId', 'passportArea_id', 'birthArea_id']:\n",
    "    mask_null = (df_player[col].isnull())|(df_player[col] == 'null')\n",
    "    df_player.loc[mask_null, col] = np.nan\n",
    "    df_player[col] = df_player[col].astype(np.float32)\n",
    "df_player.rename({'wyId': 'player_id'}, axis=1, inplace=True)\n",
    "df_player.to_parquet(os.path.join(DATA_FOLDER, 'player.parquet'))\n",
    "df_player.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142 entries, 0 to 141\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   city             142 non-null    object\n",
      " 1   name             142 non-null    object\n",
      " 2   team_id          142 non-null    int64 \n",
      " 3   officialName     142 non-null    object\n",
      " 4   type             142 non-null    object\n",
      " 5   area_name        142 non-null    object\n",
      " 6   area_id          142 non-null    int32 \n",
      " 7   area_alpha3code  142 non-null    object\n",
      " 8   area_alpha2code  142 non-null    object\n",
      "dtypes: int32(1), int64(1), object(7)\n",
      "memory usage: 9.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_team = pd.read_json(os.path.join(DATA_FOLDER, 'json', 'team.json'), encoding='unicode-escape')\n",
    "df_team = _split_dict_col(df_team, 'area')\n",
    "df_team['area_id'] = df_team.area_id.astype(np.int32)\n",
    "df_team.to_parquet(os.path.join(DATA_FOLDER, 'team.parquet'))\n",
    "df_team.rename({'wyId': 'team_id'}, axis=1, inplace=True)\n",
    "team_rename = {'Real Club Celta de Vigo': 'Celta Vigo',\n",
    "               'Valencia Club de Fútbol': 'Valencia',\n",
    "               'FC Barcelona': 'Barcelona',\n",
    "               'Real Betis Balompié': 'Real Betis',\n",
    "               'Girona FC': 'Girona',\n",
    "               'CD Leganés': 'Leganés',\n",
    "               'Real Sociedad de Fútbol': 'Real Sociedad',\n",
    "               'Real Club Deportivo de La Coruña': 'Deportivo La Coruna',\n",
    "               'Sevilla FC': 'Sevilla',\n",
    "               'Getafe Club de Fútbol': 'Getafe',\n",
    "               'Athletic Club Bilbao': 'Athletic Bilbao',\n",
    "               'Real Madrid Club de Fútbol': 'Real Madrid',\n",
    "               'Málaga Club de Fútbol': 'Málaga',\n",
    "               'Levante UD': 'Levante',\n",
    "               'Reial Club Deportiu Espanyol': 'Espanyol',\n",
    "               'UD Las Palmas': 'Las Palmas',\n",
    "               'SD Eibar': 'Eibar',\n",
    "               'Villarreal Club de Fútbol': 'Villarreal',\n",
    "               'Club Atlético de Madrid': 'Atlético Madrid',\n",
    "               'Korea Republic': 'South Korea'}\n",
    "df_team.officialName.replace(team_rename, inplace=True)\n",
    "df_team.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   competition_name          7 non-null      object \n",
      " 1   competition_id            7 non-null      int64  \n",
      " 2   format                    7 non-null      object \n",
      " 3   type                      7 non-null      object \n",
      " 4   area_name                 7 non-null      object \n",
      " 5   area_id                   5 non-null      float32\n",
      " 6   area_alpha3code           7 non-null      object \n",
      " 7   area_alpha2code           7 non-null      object \n",
      " 8   competition_country_name  7 non-null      object \n",
      " 9   competition_gender        7 non-null      object \n",
      " 10  season_name               7 non-null      object \n",
      "dtypes: float32(1), int64(1), object(9)\n",
      "memory usage: 716.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_competition = pd.read_json(os.path.join(DATA_FOLDER, 'json', 'competition.json'), encoding='unicode-escape')\n",
    "df_competition = _split_dict_col(df_competition, 'area')\n",
    "# if the area id is '0' as text for internationals set to missing\n",
    "df_competition.loc[df_competition.format=='International cup', 'area_id'] = np.nan\n",
    "df_competition['area_id'] = df_competition.area_id.astype(np.float32)\n",
    "# make same format as StatsBomb: competition_country_name\n",
    "mask = df_competition.type=='club'\n",
    "df_competition.loc[mask, 'competition_country_name'] = df_competition.loc[mask, 'area_name']\n",
    "mask = df_competition.type=='international'\n",
    "df_competition.loc[mask, 'competition_country_name'] = 'International'\n",
    "# add gender\n",
    "df_competition['competition_gender'] = 'male'\n",
    "# replace with competition real names\n",
    "df_competition.name.replace({'Spanish first division': 'La Liga',\n",
    "                             'World Cup': 'FIFA World Cup',\n",
    "                             'Italian first division': 'Serie A',\n",
    "                             'English first division': 'Premier League',\n",
    "                             'French first division': 'Ligue 1',\n",
    "                             'German first division': 'Bundesliga',\n",
    "                             'European Championship': 'UEFA Euro'}, inplace=True)\n",
    "# rename competition name\n",
    "df_competition.rename({'name': 'competition_name', 'wyId': 'competition_id'}, axis=1, inplace=True)\n",
    "# add season name\n",
    "df_competition.loc[df_competition.type == 'club', 'season_name'] = '2017/2018'\n",
    "df_competition.loc[df_competition.competition_name == 'UEFA Euro', 'season_name'] = '2016'\n",
    "df_competition.loc[df_competition.competition_name == 'FIFA World Cup', 'season_name'] = '2018'\n",
    "df_competition.to_parquet(os.path.join(DATA_FOLDER, 'competition.parquet'))\n",
    "df_competition.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not interested in formations or lineups so did not parse them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of match files\n",
    "match_list = glob.glob(os.path.join(DATA_FOLDER, 'json', 'matches*.json'))\n",
    "\n",
    "# loop through match files as save as seperate parquet files\n",
    "for file in match_list:\n",
    "    \n",
    "    # match dataframe\n",
    "    df_match = pd.read_json(file, encoding='unicode-escape')\n",
    "    \n",
    "    # split the team information from the teamsData column into two seperate columns\n",
    "    col = 'teamsData'\n",
    "    df_match[col] = df_match[col].apply(lambda x: {} if pd.isna(x) else x)\n",
    "    df_match['team1'] = df_match.teamsData.apply(lambda x: x[list(x.keys())[0]])\n",
    "    df_match['team2'] = df_match.teamsData.apply(lambda x: x[list(x.keys())[1]])\n",
    "    \n",
    "    # split team information stored as a dictionary into seperate columns\n",
    "    df_match = _split_dict_col(df_match, 'team1')\n",
    "    df_match = _split_dict_col(df_match, 'team2')\n",
    "    \n",
    "    # add home and away teams and scores up to extra time\n",
    "    mask = df_match.team1_side == 'home'\n",
    "    mask_et = (df_match.team1_scoreET > 0) | (df_match.team2_scoreET > 0)\n",
    "    df_match.loc[mask,'home_score'] = df_match.loc[mask,'team1_score']\n",
    "    df_match.loc[mask,'away_score'] = df_match.loc[mask,'team2_score']\n",
    "    df_match.loc[~mask,'home_score'] = df_match.loc[~mask,'team2_score']\n",
    "    df_match.loc[~mask,'away_score'] = df_match.loc[~mask,'team1_score']\n",
    "    df_match.loc[mask_et & mask,'home_score'] = df_match.loc[mask_et & mask,'team1_scoreET']\n",
    "    df_match.loc[mask_et & mask,'away_score'] = df_match.loc[mask_et & mask,'team2_scoreET']\n",
    "    df_match.loc[mask_et & ~mask,'home_score'] = df_match.loc[mask_et & ~mask,'team2_scoreET']\n",
    "    df_match.loc[mask_et & ~mask,'away_score'] = df_match.loc[mask_et & ~mask,'team1_scoreET']    \n",
    "    \n",
    "    # add away/ home team info\n",
    "    df_match.loc[mask, 'home_team_id'] = df_match.loc[mask, 'team1_teamId']\n",
    "    df_match.loc[~mask, 'home_team_id'] = df_match.loc[~mask, 'team2_teamId']\n",
    "    df_match.loc[mask, 'away_team_id'] = df_match.loc[mask, 'team2_teamId']\n",
    "    df_match.loc[~mask, 'away_team_id'] = df_match.loc[~mask, 'team1_teamId']\n",
    "    \n",
    "    # add away/home coach info\n",
    "    df_match.loc[mask, 'home_team_coach_id'] = df_match.loc[mask, 'team1_coachId']\n",
    "    df_match.loc[~mask, 'home_team_coach_id'] = df_match.loc[~mask, 'team2_coachId']\n",
    "    df_match.loc[mask, 'away_team_coach_id'] = df_match.loc[mask, 'team2_coachId']\n",
    "    df_match.loc[~mask, 'away_team_coach_id'] = df_match.loc[~mask, 'team1_coachId']\n",
    "\n",
    "    # format date columns\n",
    "    df_match['dateutc'] = pd.to_datetime(df_match.dateutc)\n",
    "    df_match['kick_off'] = pd.to_datetime(df_match.date.astype(str).str[:-6])\n",
    "    \n",
    "    # rename columns\n",
    "    df_match.rename({'wyId': 'match_id',\n",
    "                     'gameweek': 'match_week',\n",
    "                     'seasonId': 'season_id',\n",
    "                     'competitionId': 'competition_id',\n",
    "                     'venue': 'stadium_name'}, axis=1, inplace=True)\n",
    "    \n",
    "    # add competition info\n",
    "    df_match = df_match.merge(df_competition[['competition_id',\n",
    "                                              'competition_country_name',\n",
    "                                              'competition_name',\n",
    "                                              'season_name',\n",
    "                                              'competition_gender']], on='competition_id', how='left')\n",
    "    \n",
    "    # add team info\n",
    "    df_match = df_match.merge(df_team[['team_id', 'officialName']],\n",
    "                              left_on='home_team_id', right_on='team_id', how='left')\n",
    "    df_match = df_match.merge(df_team[['team_id', 'officialName']],\n",
    "                              left_on='away_team_id', right_on='team_id', how='left', suffixes=['_home', '_away'])\n",
    "    \n",
    "    df_match.rename({'officialName_home': 'home_team_name',\n",
    "                     'officialName_away': 'away_team_name'}, axis=1, inplace=True)\n",
    "    \n",
    "    # drop columns\n",
    "    df_match.drop(['date', 'status', 'winner', 'referees', 'team_id_away', 'team_id_home',\n",
    "                   'team1_formation_bench', 'team1_formation_lineup', 'team1_formation_substitutions',\n",
    "                   'team2_formation_bench', 'team2_formation_lineup', 'team2_formation_substitutions',\n",
    "                   'team1_hasFormation', 'team2_hasFormation',\n",
    "                   'team1_score', 'team1_scoreP', 'team1_scoreHT', 'team1_scoreET',\n",
    "                   'team2_score', 'team2_scoreP', 'team2_scoreHT', 'team2_scoreET',\n",
    "                   'teamsData', 'team1_teamId', 'team2_teamId', 'team2_side',\n",
    "                   'team1_side', 'team1_coachId', 'team2_coachId'], axis=1, inplace=True)\n",
    "    \n",
    "    save_path = os.path.join(DATA_FOLDER, 'match_raw', f'{os.path.basename(file)[:-4]}parquet')\n",
    "    df_match.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get matches as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1941 entries, 0 to 63\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   roundId                   1941 non-null   int64         \n",
      " 1   match_week                1941 non-null   int64         \n",
      " 2   season_id                 1941 non-null   int64         \n",
      " 3   dateutc                   1941 non-null   datetime64[ns]\n",
      " 4   stadium_name              1941 non-null   object        \n",
      " 5   match_id                  1941 non-null   int64         \n",
      " 6   label                     1941 non-null   object        \n",
      " 7   duration                  1941 non-null   object        \n",
      " 8   competition_id            1941 non-null   int64         \n",
      " 9   home_score                1941 non-null   float64       \n",
      " 10  away_score                1941 non-null   float64       \n",
      " 11  home_team_id              1941 non-null   float64       \n",
      " 12  away_team_id              1941 non-null   float64       \n",
      " 13  home_team_coach_id        1941 non-null   float64       \n",
      " 14  away_team_coach_id        1941 non-null   float64       \n",
      " 15  kick_off                  1941 non-null   datetime64[ns]\n",
      " 16  competition_country_name  1941 non-null   object        \n",
      " 17  competition_name          1941 non-null   object        \n",
      " 18  season_name               1941 non-null   object        \n",
      " 19  competition_gender        1941 non-null   object        \n",
      " 20  home_team_name            1941 non-null   object        \n",
      " 21  away_team_name            1941 non-null   object        \n",
      " 22  groupName                 115 non-null    object        \n",
      "dtypes: datetime64[ns](2), float64(6), int64(5), object(10)\n",
      "memory usage: 363.9+ KB\n"
     ]
    }
   ],
   "source": [
    "match_files = glob.glob(os.path.join(DATA_FOLDER, 'match_raw', '*.parquet'))\n",
    "df_match = pd.concat([pd.read_parquet(file) for file in match_files])\n",
    "df_match.to_parquet(os.path.join(DATA_FOLDER, 'match.parquet'))\n",
    "df_match.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_England.json\n",
      "events_European_Championship.json\n",
      "events_France.json\n",
      "events_Germany.json\n",
      "events_Italy.json\n",
      "events_Spain.json\n",
      "events_World_Cup.json\n"
     ]
    }
   ],
   "source": [
    "# list of event files\n",
    "events_list = glob.glob(os.path.join(DATA_FOLDER, 'json', 'events*.json'))\n",
    "\n",
    "# loop through event files as save as seperate parquet files\n",
    "for file in events_list:\n",
    "    \n",
    "    print(os.path.basename(file))\n",
    "    \n",
    "    # load as dataframe\n",
    "    df_event = pd.read_json(file, encoding='unicode-escape')\n",
    "    \n",
    "    # split start and end positions\n",
    "    _split_location_cols(df_event, 'positions', ['start', 'end'])\n",
    "    \n",
    "    # create seperate columns for the x/y coordinates\n",
    "    for col in ['start', 'end']:\n",
    "        df_event = _split_dict_col(df_event, col)\n",
    "        \n",
    "    # create a seperate column for each tag in the dictionary\n",
    "    df_new = pd.DataFrame(df_event['tags'].tolist(), index=df_event.index)\n",
    "    for tag in df_new.columns:\n",
    "        df_new.loc[df_new[tag].notnull(), tag] = df_new.loc[df_new[tag].notnull(), tag].apply(lambda x: x['id'])\n",
    "        \n",
    "    # summarise tag id columns into boolean columns for each tag and a string column for position \n",
    "    cols_to_drop = df_new.columns\n",
    "    df_tag = pd.read_json(os.path.join(DATA_FOLDER, 'json', 'event_tag.json'))\n",
    "    position_tags = df_tag.loc[df_tag.tag_name.str[:8] == 'position', 'tag_id'].values\n",
    "    for i, row in df_tag.iterrows():\n",
    "        if row['tag_id'] not in position_tags:\n",
    "            df_new.loc[(df_new==row['tag_id']).any(axis=1), row['tag_name']] = True\n",
    "        else:\n",
    "            df_new.loc[(df_new==row['tag_id']).any(axis=1), 'position'] = row['tag_name']\n",
    "            \n",
    "    # remove 'position' and '_' from text in the position column\n",
    "    df_new['position'] = df_new.position.str[9:].str.replace('_', ' ')\n",
    "    df_new.loc[df_new['position'].isnull(), 'position'] = None\n",
    "    \n",
    "    # replace missing with False for boolean columns\n",
    "    other_tags = df_tag.loc[df_tag.tag_name.str[:8] != 'position', 'tag_name'].values\n",
    "    df_new[other_tags] = df_new[other_tags].replace({np.nan: False})\n",
    "    \n",
    "    # drop tag id columns\n",
    "    df_new.drop(cols_to_drop, axis=1, inplace=True)                                               \n",
    "                                        \n",
    "    # add tags to the dataset\n",
    "    df_event = pd.concat([df_event, df_new], axis=1)\n",
    "    \n",
    "    # drop tag column\n",
    "    df_event.drop('tags', axis=1, inplace=True)\n",
    "    \n",
    "    # deal with blank subEventId\n",
    "    df_event.loc[df_event.subEventId=='', 'subEventId'] = None\n",
    "    df_event['subEventId'] = df_event['subEventId'].astype(np.float32)\n",
    "    \n",
    "    # rename columns for consistency with other datasets\n",
    "    df_event.rename({'playerId': 'player_id',\n",
    "                     'start_y': 'y',\n",
    "                     'start_x': 'x',\n",
    "                     'matchId': 'match_id',\n",
    "                     'teamId': 'team_id',}, axis=1, inplace=True)\n",
    "    \n",
    "    # save to parquet\n",
    "    save_path = os.path.join(DATA_FOLDER, 'event_raw', f'{os.path.basename(file)[:-4]}parquet')\n",
    "    df_event.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get events as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3251294 entries, 0 to 647371\n",
      "Data columns (total 51 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   eventId              3251294 non-null  int64  \n",
      " 1   subEventName         3251294 non-null  object \n",
      " 2   player_id            3251294 non-null  int64  \n",
      " 3   match_id             3251294 non-null  int64  \n",
      " 4   eventName            3251294 non-null  object \n",
      " 5   team_id              3251294 non-null  int64  \n",
      " 6   matchPeriod          3251294 non-null  object \n",
      " 7   eventSec             3251294 non-null  float64\n",
      " 8   subEventId           3243112 non-null  float32\n",
      " 9   id                   3251294 non-null  int64  \n",
      " 10  y                    3251294 non-null  int64  \n",
      " 11  x                    3251294 non-null  int64  \n",
      " 12  end_y                3250553 non-null  float64\n",
      " 13  end_x                3250553 non-null  float64\n",
      " 14  goal                 3251294 non-null  bool   \n",
      " 15  own_goal             3251294 non-null  bool   \n",
      " 16  assist               3251294 non-null  bool   \n",
      " 17  key_pass             3251294 non-null  bool   \n",
      " 18  counter_attack       3251294 non-null  bool   \n",
      " 19  left_foot            3251294 non-null  bool   \n",
      " 20  right_foot           3251294 non-null  bool   \n",
      " 21  other_body_part      3251294 non-null  bool   \n",
      " 22  direct               3251294 non-null  bool   \n",
      " 23  indirect             3251294 non-null  bool   \n",
      " 24  dangerous_ball_lost  3251294 non-null  bool   \n",
      " 25  blocked              3251294 non-null  bool   \n",
      " 26  high                 3251294 non-null  bool   \n",
      " 27  low                  3251294 non-null  bool   \n",
      " 28  interception         3251294 non-null  bool   \n",
      " 29  clearance            3251294 non-null  bool   \n",
      " 30  opportunity          3251294 non-null  bool   \n",
      " 31  feint                3251294 non-null  bool   \n",
      " 32  missed_ball          3251294 non-null  bool   \n",
      " 33  free_space_right     3251294 non-null  bool   \n",
      " 34  free_space_left      3251294 non-null  bool   \n",
      " 35  take_on_left         3251294 non-null  bool   \n",
      " 36  take_on_right        3251294 non-null  bool   \n",
      " 37  sliding_tackle       3251294 non-null  bool   \n",
      " 38  anticipated          3251294 non-null  bool   \n",
      " 39  anticipation         3251294 non-null  bool   \n",
      " 40  red_card             3251294 non-null  bool   \n",
      " 41  yellow_card          3251294 non-null  bool   \n",
      " 42  second_yellow_card   3251294 non-null  bool   \n",
      " 43  position             51618 non-null    object \n",
      " 44  through              3251294 non-null  bool   \n",
      " 45  fairplay             3251294 non-null  bool   \n",
      " 46  lost                 3251294 non-null  bool   \n",
      " 47  neutral              3251294 non-null  bool   \n",
      " 48  won                  3251294 non-null  bool   \n",
      " 49  accurate             3251294 non-null  bool   \n",
      " 50  not_accurate         3251294 non-null  bool   \n",
      "dtypes: bool(36), float32(1), float64(3), int64(7), object(4)\n",
      "memory usage: 496.1+ MB\n"
     ]
    }
   ],
   "source": [
    "event_files = glob.glob(os.path.join(DATA_FOLDER, 'event_raw', '*.parquet'))\n",
    "df_event = pd.concat([pd.read_parquet(file) for file in event_files])\n",
    "df_event.sort_values(['match_id', 'matchPeriod', 'eventSec'], inplace=True)\n",
    "df_event.to_parquet(os.path.join(DATA_FOLDER, 'event.parquet'))\n",
    "df_event.info(verbose=True, null_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
