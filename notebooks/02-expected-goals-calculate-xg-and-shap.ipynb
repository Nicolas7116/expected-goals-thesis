{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import load\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lgbm = pd.read_parquet(os.path.join('..', 'data', 'modelling', 'lgbm.parquet'))\n",
    "df_lgbm.sort_index(inplace=True)\n",
    "df_X = df_lgbm.drop(['goal', 'split', 'match_id', 'wyscout_id', 'statsbomb_id'], axis=1).copy()\n",
    "model = load(os.path.join('..', 'models', 'lgbm_model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_X.columns\n",
    "features = np.array([f.replace('_', ' ') for f in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg predictions. First have to fit to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm['xg'] = model.predict_proba(df_X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a datafrane if the uncalibrated/ calibrated probabilities for each of the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model.calibrated_classifiers_\n",
    "estimators = [model.base_estimator for model in models]\n",
    "probabilities = []\n",
    "for i in range(3):\n",
    "    probabilities.append(estimators[i].predict_proba(df_X)[:, 1])\n",
    "    probabilities.append(models[i].predict_proba(df_X)[:, 1])\n",
    "df_probabilities = pd.DataFrame(np.vstack(probabilities).T, columns=['uncalibrated0', 'calibrated0',\n",
    "                                                                     'uncalibrated1', 'calibrated1',\n",
    "                                                                     'uncalibrated2', 'calibrated2'])\n",
    "df_probabilities['calibrated'] = model.predict_proba(df_X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shap values from shap package (estimate as probabilites rather than log odds deviation from bias).\n",
    "Done in loop for the estimators in the calibrated classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 64163/64169 [20:28<00:00]        "
     ]
    }
   ],
   "source": [
    "# this takes a while, but calculates the contributions as probabilities\n",
    "# https://github.com/slundberg/shap/issues/963\n",
    "sample = data=df_X.sample(500).astype(np.float32)\n",
    "contributions = []\n",
    "for estimator in estimators:\n",
    "    explainer = shap.TreeExplainer(estimator, data=sample, model_output='probability')\n",
    "    shap_values_probability = explainer.shap_values(df_X)\n",
    "    bias = explainer.expected_value\n",
    "    df_contributions_probability = pd.DataFrame(shap_values_probability, columns=features)\n",
    "    df_contributions_probability['bias'] = bias\n",
    "    contributions.append(df_contributions_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the uncalibrated contributions to sum to the calibrated predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_contributions = []\n",
    "for i in range(3):\n",
    "    scaled = (contributions[i]\n",
    "              .divide(df_probabilities[f'uncalibrated{i}'], axis=0)\n",
    "              .multiply(df_probabilities[f'calibrated{i}'], axis=0))\n",
    "    scaled_contributions.append(scaled)   \n",
    "df_scaled_contributions = (scaled_contributions[0] + scaled_contributions[1] + scaled_contributions[2])/3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove a few where the scaled contributions don't match the actual xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64169, 26)\n",
      "(64169, 4)\n"
     ]
    }
   ],
   "source": [
    "df_base = df_lgbm[['match_id', 'wyscout_id', 'statsbomb_id', 'xg']]\n",
    "print(df_scaled_contributions.shape)\n",
    "print(df_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where scaled contributions not within 5 decimal places of the Xg value set to missing (some rounding errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_contributions.reset_index(drop=True, inplace=True)\n",
    "df_base.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_contributions_not_equal = ((df_scaled_contributions.sum(axis=1) - df_base.xg).abs().round(5) > 0)\n",
    "df_scaled_contributions[mask_contributions_not_equal] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a dataframe with the contirubtions, match and event ids, and the contributions and xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_base.merge(df_scaled_contributions,\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                        how='left',\n",
    "                        validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64169 entries, 0 to 64168\n",
      "Data columns (total 30 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   match_id             64169 non-null  int64  \n",
      " 1   wyscout_id           42702 non-null  float64\n",
      " 2   statsbomb_id         21467 non-null  object \n",
      " 3   xg                   64169 non-null  float64\n",
      " 4   shot type name       64058 non-null  float64\n",
      " 5   x                    64058 non-null  float64\n",
      " 6   y                    64058 non-null  float64\n",
      " 7   counter attack       64058 non-null  float64\n",
      " 8   fast break           64058 non-null  float64\n",
      " 9   strong foot          64058 non-null  float64\n",
      " 10  body part name       64058 non-null  float64\n",
      " 11  assist type          64058 non-null  float64\n",
      " 12  pass end y           64058 non-null  float64\n",
      " 13  pass end x           64058 non-null  float64\n",
      " 14  pass switch          64058 non-null  float64\n",
      " 15  pass cross           64058 non-null  float64\n",
      " 16  pass cut back        64058 non-null  float64\n",
      " 17  pass height name     64058 non-null  float64\n",
      " 18  pass technique name  64058 non-null  float64\n",
      " 19  carry length         64058 non-null  float64\n",
      " 20  shot one on one      64058 non-null  float64\n",
      " 21  shot open goal       64058 non-null  float64\n",
      " 22  under pressure       64058 non-null  float64\n",
      " 23  area shot            64058 non-null  float64\n",
      " 24  area goal            64058 non-null  float64\n",
      " 25  n angle              64058 non-null  float64\n",
      " 26  goalkeeper x         64058 non-null  float64\n",
      " 27  goalkeeper y         64058 non-null  float64\n",
      " 28  smart pass           64058 non-null  float64\n",
      " 29  bias                 64058 non-null  float64\n",
      "dtypes: float64(28), int64(1), object(1)\n",
      "memory usage: 14.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_base.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_parquet(os.path.join('..', 'data', 'modelling', 'xg_shap.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Shap to plot a contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=2\n",
    "shap.force_plot(df_scaled_contributions.iloc[idx, -1], \n",
    "                df_scaled_contributions.iloc[idx, :-1].values,\n",
    "                features=df_X.iloc[idx].values,\n",
    "                feature_names=features, matplotlib=True, show=False)\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join('..', 'figures', '08_shap_example.png'), bbox_inches = 'tight', pad_inches = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
